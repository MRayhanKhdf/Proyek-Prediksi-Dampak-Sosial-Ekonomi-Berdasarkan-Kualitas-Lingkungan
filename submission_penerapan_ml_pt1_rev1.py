# -*- coding: utf-8 -*-
"""Submission_Penerapan ML PT1_Rev1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OdhcyoW82VdV33XfL_1NiA-kRhlyODH-

# Proyek Prediksi Dampak Sosial-Ekonomi Berdasarkan Kualitas Lingkungan
- **Nama:** [Muhammad Rayhan Khadafi]
- **Email:** [M.rayhankhdf@gmail.com]
- **ID Dicoding:** [A200YBM343]

Notebook ini mencakup analisis regresi dan klasifikasi untuk memprediksi dampak dan korelasi kualitas udara, polusi air, dan GDP per-kapita pada sosial-ekonomi.

## Mount Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Import Library"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression

"""## Load Dataset
Memuat dataset `Cities1.csv`, `WHO_PM.csv`, dan `gdp_per_capita.csv`
"""

# Sesuaikan path jika perlu
cities_df = pd.read_csv('/content/drive/MyDrive/Dicoding1/Submit ML Terapan/Submisi_1/Cities1.csv')
who_pm_df = pd.read_csv('/content/drive/MyDrive/Dicoding1/Submit ML Terapan/Submisi_1/WHO_PM.csv')
gdp_df = pd.read_csv('/content/drive/MyDrive/Dicoding1/Submit ML Terapan/Submisi_1/gdp_per_capita.csv')

# Preview data
display(cities_df.head())
display(who_pm_df.head())
display(gdp_df.head())

"""## Data Understanding
### Cities1.csv
### WHO_PM.csv
### gdp_per_capita.csv



"""

print('Cities1 shape:', cities_df.shape)
print('Missing in Cities1:')
print(cities_df.isnull().sum())
cities_df.head()

print('\nWHO_PM shape:', who_pm_df.shape)
print('Missing in WHO_PM:')
print(who_pm_df.isnull().sum())
who_pm_df.head()

print('\ngdp_per_capita shape:', gdp_df.shape)
print('Missing in gdp_per_capita:')
print(gdp_df.isnull().sum())
gdp_df.head()

"""## EDA (Exploratory Data Analysis)
### Statistik Deskriptif dan Visualisasi
"""

# Statistik deskriptif
display(cities_df.describe(include='all'))
display(who_pm_df['Value'].describe())

# Histogram AirQuality dan WaterPollution
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.histplot(cities_df['AirQuality'].dropna(), kde=True)
plt.title('Distribusi AirQuality')
plt.subplot(1,2,2)
sns.histplot(cities_df['WaterPollution'].dropna(), kde=True)
plt.title('Distribusi WaterPollution')
plt.show()

"""- Pola Distribusi	pada `AirQuality` Menyebar dengan puncak tinggi di 90-100. Pada `WaterPollution`	Tajam di nilai 50 (terindikasi outlier/default)
- Kualitas Data pada `AirQuality`	Cukup bervariasi dan informatif. Pada `WaterPollution`	Perlu dicek ulang nilai 50 apakah valid
- Interpretasi pada `AirQuality` Umum	Banyak kota dengan udara bagus. Pada `WaterPollution`	Banyak kota terindikasi pencemaran air sedang (atau data bias)
"""

print(who_pm_df['Value'].describe())

# Ekstrak nilai numerik dari kolom 'Value'
who_pm_df['Numeric_Value'] = who_pm_df['Value'].str.extract(r'(\d+\.?\d*)').astype(float)

# Filter data outlier
clean_pm = who_pm_df[(who_pm_df['Numeric_Value'] > 0) & (who_pm_df['Numeric_Value'] < 500)]

display(clean_pm.head())

"""Filter Data Outlier"""

# Histogram PM2.5
plt.figure(figsize=(6,4))
sns.histplot(clean_pm['Numeric_Value'].dropna(), bins=30, kde=True)  # Use the cleaned numeric column
plt.xlim(0, 100)  # sesuaikan rentang jika PM2.5 dalam satuan µg/m³
plt.title('Distribusi PM2.5 (Value)')
plt.xlabel('Konsentrasi PM2.5 (µg/m³)')
plt.ylabel('Frekuensi')
plt.show()

"""- Mayoritas pengukuran konsentrasi PM2.5 berada di bawah 40 µg/m³.

- Ada ekor panjang ke kanan → menunjukkan adanya beberapa kejadian dengan konsentrasi PM2.5 tinggi (mungkin karena polusi ekstrem sesekali).

- Kurva KDE memberikan gambaran halus bentuk distribusi dibandingkan hanya batang histogram.
"""

# Korelasi awal antara AirQuality dan WaterPollution
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Plot scatter awal
plt.figure(figsize=(6, 4))
sns.scatterplot(data=cities_df, x='AirQuality', y='WaterPollution')
plt.title('Scatter AirQuality vs WaterPollution')
plt.show()

# Hitung nilai korelasi Pearson
corr_value = cities_df[['AirQuality', 'WaterPollution']].corr().iloc[0, 1]
print(f'Korelasi Pearson antara AirQuality dan WaterPollution: {corr_value:.3f}')

"""- Scatter plot memperlihatkan pola penyebaran.
- Korelasi Pearson bernilai -0.454, artinya ada korelasi negatif sedang: semakin baik kualitas udara (AirQuality ↑), maka tingkat pencemaran air (WaterPollution ↓) cenderung menurun.
"""

# Scatter plot dengan garis regresi (linear model plot)
sns.lmplot(data=cities_df, x='AirQuality', y='WaterPollution', height=4, aspect=1.5)
plt.title('Linear Regression AirQuality vs WaterPollution')
plt.show()

"""- Garis miring ke bawah memperkuat bahwa hubungan bersifat negatif.
- Cocok untuk analisis prediktif sederhana.
"""

# Alternatif visualisasi: hexbin plot untuk kepadatan titik
plt.figure(figsize=(6, 4))
plt.hexbin(cities_df['AirQuality'], cities_df['WaterPollution'], gridsize=30, cmap='Blues', mincnt=1)
plt.colorbar(label='Jumlah Titik')
plt.xlabel('AirQuality')
plt.ylabel('WaterPollution')
plt.title('Hexbin Plot: AirQuality vs WaterPollution')
plt.tight_layout()
plt.show()

"""- Warna biru yang lebih gelap menunjukkan area dengan lebih banyak data.
- Memperkuat pola penyebaran dan tren korelasi negatif.

## Data Preparation
### Menggabungkan Cities1 dan WHO_PM berdasarkan nama kota, menghitung UEQ Index, dan menyiapkan fitur.
"""

# Merge dataset pada kolom City = Location
merged_df = pd.merge(cities_df, who_pm_df, left_on='City', right_on='Location', how='left')

# Normalisasi AirQuality dan PM2.5
merged_df['AirQuality_norm'] = (merged_df['AirQuality'] - merged_df['AirQuality'].min()) / \
    (merged_df['AirQuality'].max() - merged_df['AirQuality'].min())

# Convert 'Value' to numeric, coercing errors
merged_df['PM25'] = pd.to_numeric(merged_df['Value'], errors='coerce')

# Fill missing PM25 values with the mean
merged_df['PM25'].fillna(merged_df['PM25'].mean(), inplace=True)

merged_df['PM25_norm'] = (merged_df['PM25'] - merged_df['PM25'].min()) / \
    (merged_df['PM25'].max() - merged_df['PM25'].min())

# Hitung UEQ Index sebagai rata-rata normalisasi AirQuality dan PM25
merged_df['UEQ_Index'] = (merged_df['AirQuality_norm'] + merged_df['PM25_norm']) / 2

# Tampilkan hasil awal
display(merged_df[['City', 'AirQuality', 'PM25', 'UEQ_Index']].head())

"""## Integrasi GDP per Kapita
Memilih kolom GDP tahun 2019 dari `gdp_per_capita.csv` dan menggabungkannya berdasarkan negara.
"""

# Ekstrak GDP per kapita tahun 2019
gdp_2019 = gdp_df[['Country Name', '2019']].copy()
gdp_2019.columns = ['Country', 'GDP_2019']

# Merge dengan merged_df berdasarkan kolom Country
merged_df = pd.merge(merged_df, gdp_2019, on='Country', how='left')

# Tampilkan beberapa baris setelah merge
display(merged_df[['City', 'Country', 'UEQ_Index', 'WaterPollution', 'GDP_2019']].head())

"""## Membuat Label Klasifikasi
Label klasifikasi dibentuk berdasarkan GDP tahun 2019, menggunakan median sebagai threshold.
"""

# Buat label: 1 jika GDP_2019 di atas median, else 0
median_gdp = merged_df['GDP_2019'].median()
merged_df['SocioClass'] = (merged_df['GDP_2019'] > median_gdp).astype(int)
merged_df['SocioClass'].value_counts()

"""## One-Hot Encoding Fitur Kategorikal dan Persiapan Data untuk Klasifikasi
Fitur yang akan digunakan: UEQ_Index, WaterPollution, Region, Country.
"""

# Pilih fitur dan label
features = ['UEQ_Index', 'WaterPollution', 'Region', 'Country']
X = merged_df[features]
y = merged_df['SocioClass']

# One-hot encode kolom kategorikal (Region, Country) dan scaling numerik
categorical_features = ['Region', 'Country']
numeric_features = ['UEQ_Index', 'WaterPollution']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

# Split data train-test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Modeling - Klasifikasi
Menggunakan Logistic Regression, Random Forest, dan KNN.
"""

# Pipeline untuk Logistic Regression
pipe_lr = Pipeline(steps=[('preprocessor', preprocessor),
                           ('classifier', LogisticRegression(max_iter=1000))])
pipe_lr.fit(X_train, y_train)
y_pred_lr = pipe_lr.predict(X_test)

# Pipeline untuk Random Forest
pipe_rf = Pipeline(steps=[('preprocessor', preprocessor),
                           ('classifier', RandomForestClassifier(random_state=42))])
pipe_rf.fit(X_train, y_train)
y_pred_rf = pipe_rf.predict(X_test)

# Pipeline untuk KNN
pipe_knn = Pipeline(steps=[('preprocessor', preprocessor),
                           ('classifier', KNeighborsClassifier())])
pipe_knn.fit(X_train, y_train)
y_pred_knn = pipe_knn.predict(X_test)

# Tampilkan classification report untuk tiap model
print('Logistic Regression Report:')
print(classification_report(y_test, y_pred_lr))
print('Random Forest Report:')
print(classification_report(y_test, y_pred_rf))
print('KNN Report:')
print(classification_report(y_test, y_pred_knn))

"""- Logistic Regression – Accuracy ≈ 0.99

- Random Forest Classifier – Accuracy ≈ 0.99

- KNN – Accuracy ≈ 0.98
Setelah tuning dengan GridSearchCV, Random Forest terbaik menghasilkan akurasi ≈ 0.9919, precision/recall ≈ 0.99 untuk kedua kelas.

## Hyperparameter Tuning Random Forest dengan GridSearchCV
"""

# Definisikan pipeline untuk tuning
rf_param_grid = {
    'classifier__n_estimators': [50, 100, 200],
    'classifier__max_depth': [None, 10, 20],
    'classifier__min_samples_split': [2, 5]
}

pipe_rf_tune = Pipeline(steps=[('preprocessor', preprocessor),
                               ('classifier', RandomForestClassifier(random_state=42))])
grid_rf = GridSearchCV(pipe_rf_tune, rf_param_grid, cv=5, n_jobs=-1, scoring='accuracy')
grid_rf.fit(X_train, y_train)

# Tampilkan best parameters
print('Best Parameters Random Forest:', grid_rf.best_params_)

"""## Evaluasi Model Terbaik
Gunakan model terbaik dari GridSearchCV, lalu tampilkan classification report.
"""

# Evaluasi using best RF
best_rf = grid_rf.best_estimator_
y_pred_best_rf = best_rf.predict(X_test)
print('Best Random Forest Report:')
print(classification_report(y_test, y_pred_best_rf))
print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred_best_rf))
print('Accuracy:', accuracy_score(y_test, y_pred_best_rf))

"""- Akurasi terbaik Random Forest = 99%

## Modeling - Regresi
Menampilkan kembali modeling regresi sebagai fallback.
"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

# Regresi: Linear Regression dan Random Forest Regressor (dengan data kontinu)
data_reg = merged_df.dropna(subset=['UEQ_Index', 'WaterPollution', 'GDP_2019'])
X_reg = data_reg[['UEQ_Index', 'WaterPollution']]
y_reg = data_reg['GDP_2019']
Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

# Linear Regression
lr_reg = LinearRegression()
lr_reg.fit(Xr_train, yr_train)
y_pred_lr_reg = lr_reg.predict(Xr_test)

# Random Forest Regressor
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(Xr_train, yr_train)
y_pred_rf_reg = rf_reg.predict(Xr_test)

# Evaluasi regresi
print('Regresi - Linear Regression MAE:', mean_absolute_error(yr_test, y_pred_lr_reg))
print('Regresi - Linear Regression R2:', r2_score(yr_test, y_pred_lr_reg))
print('Regresi - Random Forest MAE:', mean_absolute_error(yr_test, y_pred_rf_reg))
print('Regresi - Random Forest R2:', r2_score(yr_test, y_pred_rf_reg))

"""- Linear Regression – MAE ≈ 19.576, R² ≈ 0.075

- Random Forest Regressor – MAE ≈ 12.305, R² ≈ 0.612

## Kesimpulan dan Rekomendasi
#3 Model pengujian (Logistic Regression, Random Forest Classifier, dan KNN) digunakan untuk memprediksi kelas sosial ekonomi menghasilkan akurasi:
- Logistic Regression – Accuracy ≈ 0.99

- Random Forest Classifier – Accuracy ≈ 0.99

- KNN – Accuracy ≈ 0.98
Setelah tuning dengan GridSearchCV, Random Forest terbaik menghasilkan akurasi ≈ 0.9919, precision/recall ≈ 0.99 untuk kedua kelas.

#2 Model digunakan untuk memprediksi nilai GDP per kapita berdasarkan UEQ_Index dan WaterPollution:
- Linear Regression – MAE ≈ 19.576, R² ≈ 0.075

- Random Forest Regressor – MAE ≈ 12.305, R² ≈ 0.612
Yang berarti random forest regressor jauh lebih baik, kareba mampu  sekitar 61 % variansi GDP menggunakan fitur UEQ dan polusi air, sedangkan Linear Regression hanya ~7 %.

Klasifikasi: Model Random Forest Classifier terbaik, akurasi ≈ 99 %, menunjukkan indikator UEQ dan polusi air sangat berkorelasi dengan kategori GDP tinggi/rendah.

Regresi: Model Random Forest Regressor outperform Linear Regression (R² 0.61 vs 0.075), menegaskan bahwa hubungan non-linear antara kualitas lingkungan dan GDP erat.
"""